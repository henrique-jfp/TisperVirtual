#!/usr/bin/env python3
"""
Sistema de Impress√£o Inteligente para P√°ginas Web
Converte p√°ginas HTML em Markdown organizado e extrai dados estruturados
Substitui as "notas manuais" com IA avan√ßada
"""

import asyncio
import json
import os
import re
import sys
from datetime import datetime
from typing import Dict, List, Optional, Any
from urllib.parse import urlparse

import requests
from playwright.async_api import async_playwright
from bs4 import BeautifulSoup
import pdfplumber
from groq import Groq
from dotenv import load_dotenv

# Carregar vari√°veis de ambiente
load_dotenv()

class SmartWebPrinter:
    """Sistema de impress√£o inteligente de p√°ginas web"""

    def __init__(self):
        # Usar Groq em vez de OpenAI (j√° configurado no projeto)
        self.groq_client = Groq(api_key=os.getenv('LLM_API_KEY'))

        # Seletores CSS comuns para an√∫ncios e elementos indesejados
        self.ad_selectors = [
            # Google Ads
            '[id*="google_ads"]',
            '[class*="google-ads"]',
            '[id*="adsbygoogle"]',

            # Outros an√∫ncios
            '[class*="advertisement"]',
            '[class*="ads-banner"]',
            '[class*="sponsored"]',
            '[id*="banner"]',
            '[class*="popup"]',
            '[class*="modal"]',

            # Redes sociais
            '[class*="social-share"]',
            '[class*="facebook"]',
            '[class*="twitter"]',
            '[class*="instagram"]',

            # Navega√ß√£o e headers
            'nav',
            'header',
            '.header',
            '#header',

            # Footers
            'footer',
            '.footer',
            '#footer',

            # Sidebars
            'aside',
            '.sidebar',
            '#sidebar',

            # Elementos de coment√°rios
            '[class*="comment"]',
            '[class*="disqus"]'
        ]

    async def print_webpage_to_pdf(self, url: str, output_pdf: str) -> bool:
        """Faz impress√£o inteligente de p√°gina web para PDF"""
        try:
            print(f"üåê Abrindo p√°gina: {url}")

            async with async_playwright() as p:
                browser = await p.chromium.launch(headless=True)
                context = await browser.new_context(
                    viewport={'width': 1200, 'height': 800},
                    user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                )

                page = await context.new_page()

                # Configurar para esperar pelo conte√∫do
                await page.set_extra_http_headers({
                    'Accept-Language': 'pt-BR,pt;q=0.9,en;q=0.8'
                })

                # Navegar para a p√°gina
                await page.goto(url, wait_until='networkidle', timeout=30000)

                # Aguardar um pouco para carregamento din√¢mico
                await page.wait_for_timeout(3000)

                # Remover an√∫ncios e elementos indesejados
                print("üßπ Removendo an√∫ncios e elementos indesejados...")
                for selector in self.ad_selectors:
                    try:
                        elements = await page.query_selector_all(selector)
                        for element in elements:
                            try:
                                await element.evaluate('element.style.display = "none"')
                            except:
                                pass
                    except:
                        continue

                # Remover scripts e estilos inline
                await page.evaluate("""
                    // Remover scripts
                    document.querySelectorAll('script').forEach(s => s.remove());

                    // Remover estilos inline de an√∫ncios
                    document.querySelectorAll('[style*="position: fixed"]').forEach(el => el.remove());
                    document.querySelectorAll('[style*="position: absolute"][style*="z-index"]').forEach(el => el.remove());

                    // Melhorar formata√ß√£o para impress√£o
                    document.body.style.fontFamily = 'Arial, sans-serif';
                    document.body.style.lineHeight = '1.6';
                """)

                # Fazer print to PDF
                print("üìÑ Gerando PDF...")
                await page.pdf(
                    path=output_pdf,
                    format='A4',
                    print_background=True,
                    margin={'top': '1cm', 'right': '1cm', 'bottom': '1cm', 'left': '1cm'}
                )

                await browser.close()

            print(f"‚úÖ PDF gerado: {output_pdf}")
            return True

        except Exception as e:
            print(f"‚ùå Erro ao gerar PDF: {e}")
            return False

    def extract_text_from_pdf(self, pdf_path: str) -> Optional[str]:
        """Extrai texto do PDF gerado"""
        try:
            print(f"üìñ Extraindo texto de: {pdf_path}")
            text = ""

            with pdfplumber.open(pdf_path) as pdf:
                for page_num, page in enumerate(pdf.pages, 1):
                    page_text = page.extract_text()
                    if page_text:
                        text += f"## P√°gina {page_num}\n\n"
                        text += page_text.strip() + "\n\n"

            print(f"‚úÖ Texto extra√≠do ({len(pdf.pages)} p√°ginas)")
            return text

        except Exception as e:
            print(f"‚ùå Erro ao extrair texto: {e}")
            return None

    def clean_markdown(self, text: str) -> str:
        """Limpa e formata o texto extra√≠do para Markdown organizado"""
        if not text:
            return ""

        # Remove linhas vazias excessivas
        lines = text.split('\n')
        cleaned_lines = []

        prev_empty = False
        for line in lines:
            line = line.strip()
            if line:  # S√≥ adiciona linhas n√£o vazias
                cleaned_lines.append(line)
                prev_empty = False
            elif not prev_empty:  # Adiciona no m√°ximo uma linha vazia
                cleaned_lines.append('')
                prev_empty = True

        return '\n'.join(cleaned_lines)

    def extract_structured_data(self, markdown_content: str, url: str) -> Dict[str, Any]:
        """Usa IA para extrair dados estruturados do conte√∫do Markdown"""
        try:
            print("ü§ñ Analisando conte√∫do com IA...")

            # Detectar tipo de conte√∫do baseado na URL e conte√∫do
            content_type = self._detect_content_type(url, markdown_content)

            # Prompt espec√≠fico baseado no tipo de conte√∫do
            prompts = {
                'match_preview': """
                Analise esta pr√©-visualiza√ß√£o de jogo e extraia:
                - Times envolvidos (home e away)
                - Data e hor√°rio do jogo
                - Competi√ß√£o/campeonato
                - An√°lise t√°tica
                - Jogadores em destaque
                - Expectativas de placar
                - Probabilidades
                """,

                'player_news': """
                Analise esta not√≠cia sobre jogador e extraia:
                - Nome completo do jogador
                - Time atual
                - Tipo de not√≠cia (les√£o, transfer√™ncia, suspens√£o, etc.)
                - Detalhes espec√≠ficos da not√≠cia
                - Tempo de recupera√ß√£o (se les√£o)
                - Impacto no time
                - Valor da transfer√™ncia (se aplic√°vel)
                """,

                'match_report': """
                Analise este relat√≥rio de jogo e extraia:
                - Times envolvidos (home e away)
                - Placar final
                - Gols marcados (quem, quando, como)
                - Estat√≠sticas do jogo (posse, chutes, corners, etc.)
                - Melhores jogadores
                - An√°lise p√≥s-jogo
                - √Årbitro e cart√µes
                """,

                'injury_report': """
                Analise este relat√≥rio de les√µes e extraia:
                - Jogadores lesionados (nome completo)
                - Tipo de les√£o
                - Gravidade (leve, m√©dia, grave)
                - Tempo estimado de recupera√ß√£o
                - Jogos que perder√£o
                - Status atual (duvidoso, fora, etc.)
                """,

                'game_stats': """
                Analise estas estat√≠sticas de jogo e extraia:
                - Times envolvidos (home e away)
                - Data do jogo
                - Todas as estat√≠sticas dispon√≠veis (posse, chutes, corners, faltas, etc.)
                - Estat√≠sticas por jogador se dispon√≠veis
                - Placar final se mencionado
                - Formato: estat√≠stica -> valor_home x valor_away
                """,

                'general_news': """
                Analise esta not√≠cia geral de futebol e categorize:
                - T√≥pico principal
                - Times envolvidos
                - Jogadores mencionados
                - Impacto no campeonato
                - Informa√ß√µes relevantes
                """
            }

            prompt = prompts.get(content_type, prompts['general_news'])

            full_prompt = f"""
            Analise o seguinte conte√∫do de uma p√°gina web sobre futebol e extraia informa√ß√µes estruturadas.

            URL: {url}
            Tipo detectado: {content_type}

            {prompt}

            Conte√∫do:
            {markdown_content[:6000]}  # Limitar tamanho para n√£o exceder token limit

            IMPORTANTE: Responda APENAS com um JSON v√°lido. Para estat√≠sticas, use o formato:
            "statistics": {{"Posse": {{"home": "55%", "away": "45%"}}, "Chutes": {{"home": "12", "away": "8"}}}}

            INSTRU√á√ïES CR√çTICAS:
            - N√ÉO use ```json ou qualquer markdown
            - N√ÉO adicione texto antes ou depois do JSON
            - Se n√£o conseguir analisar, retorne: {{"content_type": "error", "error": "N√£o foi poss√≠vel analisar o conte√∫do"}}
            - Sempre use aspas duplas, n√£o simples

            Responda com JSON v√°lido neste formato:

            Responda com JSON v√°lido neste formato:
            {{
                "content_type": "{content_type}",
                "title": "t√≠tulo extra√≠do",
                "teams": ["time1", "time2"],
                "players": ["jogador1", "jogador2"],
                "date": "YYYY-MM-DDTHH:MM:SS",
                "data": {{
                    "score": "placar se dispon√≠vel",
                    "statistics": {{"stat_name": {{"home": "valor", "away": "valor"}}}},
                    "injuries": [{{"player": "nome", "type": "tipo", "severity": "gravidade"}}],
                    "news_details": "detalhes espec√≠ficos"
                }},
                "confidence": 0.0-1.0
            }}
            """

            response = self.groq_client.chat.completions.create(
                model="llama-3.1-8b-instant",
                messages=[{"role": "user", "content": full_prompt}],
                temperature=0.1,
                max_tokens=3000
            )

            result = response.choices[0].message.content.strip()

            # Limpar resposta da IA (remover markdown se presente)
            if result.startswith('```json'):
                result = result[7:]
            if result.endswith('```'):
                result = result[:-3]
            result = result.strip()

            # Tentar parsear JSON
            try:
                structured_data = json.loads(result)
                structured_data['source_url'] = url
                structured_data['extracted_at'] = datetime.now().isoformat()
                structured_data['raw_markdown'] = markdown_content

                print(f"‚úÖ Dados estruturados extra√≠dos (confian√ßa: {structured_data.get('confidence', 0)})")

                # Adicionar informa√ß√µes de linkagem
                structured_data['link_info'] = self._extract_link_info(structured_data, url)

                return structured_data

            except json.JSONDecodeError as e:
                print(f"‚ùå Erro ao parsear JSON da IA: {e}")
                print(f"Resposta bruta: {result[:500]}...")
                return {
                    'content_type': content_type,
                    'error': 'Failed to parse AI response',
                    'raw_response': result,
                    'source_url': url,
                    'extracted_at': datetime.now().isoformat()
                }

        except Exception as e:
            print(f"‚ùå Erro na extra√ß√£o com IA: {e}")
            return {
                'content_type': 'error',
                'error': str(e),
                'source_url': url,
                'extracted_at': datetime.now().isoformat()
            }

    def _detect_content_type(self, url: str, content: str) -> str:
        """Detecta o tipo de conte√∫do baseado na URL e texto"""
        url_lower = url.lower()
        content_lower = content.lower()

        # Detec√ß√£o baseada em URL
        if any(keyword in url_lower for keyword in ['preview', 'previsao', 'palpite']):
            return 'match_preview'

        if any(keyword in url_lower for keyword in ['injury', 'lesao', 'machucado']):
            return 'injury_report'

        if any(keyword in url_lower for keyword in ['report', 'relatorio', 'resumo']):
            return 'match_report'

        if any(keyword in url_lower for keyword in ['stats', 'statistics', 'estatisticas']):
            return 'game_stats'

        # Detec√ß√£o baseada no conte√∫do
        if any(keyword in content_lower for keyword in ['les√£o', 'lesionado', 'machucado', 'recupera√ß√£o']):
            return 'injury_report'

        if any(keyword in content_lower for keyword in ['x', 'versus', 'vs', 'confronto']) and \
           any(keyword in content_lower for keyword in ['pr√≥ximo', 'pr√≥xima', 'domingo', 's√°bado']):
            return 'match_preview'

        if any(keyword in content_lower for keyword in ['gols', 'placar', 'vit√≥ria', 'derrota']) and \
           any(keyword in content_lower for keyword in ['final', 'resultado', 'marcou']):
            return 'match_report'

        # Detec√ß√£o de estat√≠sticas
        if any(keyword in content_lower for keyword in ['posse', 'chutes', 'corners', 'faltas', 'cart√µes']):
            return 'game_stats'

        # Detec√ß√£o de not√≠cias de jogador
        if any(keyword in content_lower for keyword in ['jogador', 'atacante', 'meio', 'defensor', 'goleiro']) and \
           any(keyword in content_lower for keyword in ['transfer√™ncia', 'contrato', 'negocia√ß√£o']):
            return 'player_news'

        return 'general_news'

    def _extract_link_info(self, structured_data: Dict[str, Any], url: str) -> Dict[str, Any]:
        """Extrai informa√ß√µes para linkagem com banco de dados"""
        link_info = {
            'teams_found': [],
            'players_found': [],
            'date_found': None,
            'game_candidates': []
        }

        try:
            # Extrair times
            teams = structured_data.get('teams', [])
            if teams:
                link_info['teams_found'] = teams

            # Extrair jogadores
            players = structured_data.get('players', [])
            if players:
                link_info['players_found'] = players

            # Extrair data
            date = structured_data.get('date')
            if date:
                link_info['date_found'] = date

            # Para jogos, tentar identificar candidatos
            if structured_data.get('content_type') in ['match_report', 'game_stats', 'match_preview']:
                if len(teams) >= 2:
                    link_info['game_candidates'] = [{
                        'home_team': teams[0],
                        'away_team': teams[1],
                        'date': date,
                        'url': url
                    }]

        except Exception as e:
            print(f"Erro ao extrair link info: {e}")

        return link_info

    def check_duplicates(self, structured_data: Dict[str, Any]) -> bool:
        """Verifica se os dados j√° existem no banco para evitar duplicatas"""
        try:
            # Verifica√ß√£o b√°sica (mais avan√ßada ser√° feita no flask_api.py)
            content_type = structured_data.get('content_type', '')
            teams = structured_data.get('teams', [])
            players = structured_data.get('players', [])
            date = structured_data.get('date')

            print(f"üîç Verifica√ß√£o b√°sica de duplicatas para {content_type}...")

            # Para jogos: verificar se tem times suficientes
            if content_type in ['match_preview', 'match_report', 'game_stats'] and len(teams) >= 2:
                print(f"‚ö†Ô∏è  Jogo detectado: {teams[0]} x {teams[1]} - verifica√ß√£o avan√ßada ser√° feita na API")

            # Para les√µes: verificar se tem jogadores
            if content_type == 'injury_report' and players:
                print(f"‚ö†Ô∏è  Les√µes detectadas para {len(players)} jogadores - verifica√ß√£o avan√ßada ser√° feita na API")

            # Por enquanto, retorna False (n√£o duplicado) - verifica√ß√£o real na API
            return False

        except Exception as e:
            print(f"‚ö†Ô∏è  Erro na verifica√ß√£o b√°sica de duplicatas: {e}")
            return False

    async def process_web_content(self, url: str) -> Optional[Dict[str, Any]]:
        """Processo completo: URL ‚Üí PDF ‚Üí Markdown ‚Üí Dados Estruturados"""
        try:
            print(f"üöÄ Iniciando processamento inteligente de: {url}")

            # Passo 1: Detectar dom√≠nio e validar URL
            parsed_url = urlparse(url)
            if not parsed_url.scheme or not parsed_url.netloc:
                print("‚ùå URL inv√°lida")
                return None

            # Passo 2: Gerar PDF da p√°gina
            temp_pdf = f"temp_smart_print_{hash(url)}.pdf"

            if not await self.print_webpage_to_pdf(url, temp_pdf):
                return None

            try:
                # Passo 3: Extrair texto do PDF
                raw_text = self.extract_text_from_pdf(temp_pdf)
                if not raw_text:
                    return None

                # Passo 4: Limpar e formatar Markdown
                clean_markdown = self.clean_markdown(raw_text)

                # Passo 5: Extrair dados estruturados com IA
                structured_data = self.extract_structured_data(clean_markdown, url)

                # Passo 6: Verificar duplicatas
                if self.check_duplicates(structured_data):
                    print("‚ö†Ô∏è  Conte√∫do duplicado detectado - pulando inser√ß√£o")
                    structured_data['duplicate'] = True
                else:
                    structured_data['duplicate'] = False

                # Passo 7: Salvar Markdown para refer√™ncia
                markdown_file = f"web_content_{hash(url)}.md"
                with open(markdown_file, 'w', encoding='utf-8') as f:
                    f.write(f"# Conte√∫do Extra√≠do\n\n**Fonte:** {url}\n\n---\n\n{clean_markdown}")

                structured_data['markdown_file'] = markdown_file

                print("‚úÖ Processamento inteligente conclu√≠do!")
                return structured_data

            finally:
                # Limpar arquivo tempor√°rio
                if os.path.exists(temp_pdf):
                    os.remove(temp_pdf)
                    print(f"üßπ Arquivo tempor√°rio removido: {temp_pdf}")

        except Exception as e:
            print(f"‚ùå Erro no processamento inteligente: {e}")
            return None

async def main():
    """Fun√ß√£o principal para teste"""
    if len(sys.argv) < 2:
        print("Uso: python smart_web_printer.py <URL>")
        print("Exemplo: python smart_web_printer.py https://ge.globo.com/futebol/times/flamengo/noticia/2023/11/20/flamengo-vence-palmeiras.ghtml")
        sys.exit(1)

    url = sys.argv[1]

    printer = SmartWebPrinter()
    result = await printer.process_web_content(url)

    if result:
        print("\n" + "="*50)
        print("RESULTADO ESTRUTURADO:")
        print(json.dumps(result, indent=2, ensure_ascii=False))
    else:
        print("‚ùå Falha no processamento")

if __name__ == "__main__":
    asyncio.run(main())